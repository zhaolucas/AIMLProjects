{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background & Context\n",
    "\n",
    "The Thera bank recently saw a steep decline in the number of users of their credit card, credit cards are a good source of income for banks because of different kinds of fees charged by the banks like annual fees, balance transfer fees, and cash advance fees, late payment fees, foreign transaction fees, and others. Some fees are charged to every user irrespective of usage, while others are charged under specified circumstances.\n",
    "\n",
    "Customers’ leaving credit cards services would lead bank to loss, so the bank wants to analyze the data of customers and identify the customers who will leave their credit card services and reason for same – so that bank could improve upon those areas\n",
    "\n",
    "You as a Data scientist at Thera bank need to come up with a classification model that will help the bank improve their services so that customers do not renounce their credit cards\n",
    "\n",
    "## Objective\n",
    "\n",
    "- Explore and visualize the dataset.\n",
    "- Build a classification model to predict if the customer is going to churn or not\n",
    "- Optimize the model using appropriate techniques\n",
    "- Generate a set of insights and recommendations that will help the bank\n",
    "\n",
    "## Data Dictionary:\n",
    "\n",
    "- CLIENTNUM: Client number. Unique identifier for the customer holding the account\n",
    "- Attrition_Flag: Internal event (customer activity) variable - if the account is closed then \"Attrited Customer\" else \"Existing Customer\"\n",
    "- Customer_Age: Age in Years\n",
    "- Gender: Gender of the account holder\n",
    "- Dependent_count: Number of dependents\n",
    "- Education_Level:  Educational Qualification of the account holder - Graduate, High School, Unknown, Uneducated, College(refers to a college student), Post-Graduate, Doctorate.\n",
    "- Marital_Status: Marital Status of the account holder\n",
    "- Income_Category: Annual Income Category of the account holder\n",
    "- Card_Category: Type of Card\n",
    "- Months_on_book: Period of relationship with the bank\n",
    "- Total_Relationship_Count: Total no. of products held by the customer\n",
    "- Months_Inactive_12_mon: No. of months inactive in the last 12 months\n",
    "- Contacts_Count_12_mon: No. of Contacts between the customer and bank in the last 12 months\n",
    "- Credit_Limit: Credit Limit on the Credit Card\n",
    "- Total_Revolving_Bal: The balance that carries over from one month to the next is the revolving balance\n",
    "- Avg_Open_To_Buy: Open to Buy refers to the amount left on the credit card to use (Average of last 12 months)\n",
    "- Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n",
    "- Total_Trans_Ct: Total Transaction Count (Last 12 months)\n",
    "- Total_Ct_Chng_Q4_Q1: Ratio of the total transaction count in 4th quarter and the total transaction count in 1st quarter\n",
    "- Total_Amt_Chng_Q4_Q1: Ratio of the total transaction amount in 4th quarter and the total transaction amount in 1st quarter\n",
    "- Avg_Utilization_Ratio: Represents how much of the available credit the customer spent\n",
    "\n",
    "## Criteria\t\n",
    "\n",
    "1. Perform an Exploratory Data Analysis on the data\n",
    "- Univariate analysis - Bivariate analysis - Use appropriate visualizations to identify the patterns and insights - Any other exploratory deep dive 6\n",
    "\n",
    "2. Illustrate the insights based on EDA\n",
    "- Key meaningful observations on the relationship between variables 5\n",
    "\n",
    "\n",
    "3. Data Pre-processing\n",
    "- Prepare the data for analysis - Missing value Treatment, Outlier Detection(treat, if needed- why or why not ), Feature Engineering, Prepare data for modeling 5\n",
    "\n",
    "4. Model building - Logistic Regression\n",
    "- Make a logistic regression model - Improve model performance by up and downsampling the data - Regularize above models, if required 6\n",
    "\n",
    "5. Model building - Bagging and Boosting\n",
    "- Build Decision tree, random forest, bagging classifier models - Build Xgboost, AdaBoost, and gradient boosting models 8\n",
    "\n",
    "6. Hyperparameter tuning using grid search\n",
    "- Tune the best 3 models using grid search and provide the reason behind choosing those models - Use pipelines in hyperparameter tuning * Please note XGBoost can take a significantly longer time to run, so if you have time complexity issues then you can avoid tuning XGBoost and tune the next best 3 models 8\n",
    "\n",
    "7. Hyperparameter tuning using random search\n",
    "- Tune the best 3 models using random search and provide the reason behind choosing those models - Use pipelines in hyperparameter tuning 8\n",
    "\n",
    "8. Model Performances\n",
    "- Compare the model performance of all the models - Comment on the time taken by the grid and randomized search in optimization 5\n",
    "\n",
    "9. Actionable Insights & Recommendations\n",
    "- Business recommendations and insights 5\n",
    "\n",
    "10. Notebook - Overall quality\n",
    "- Structure and flow - Well commented code 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# libaries to help with data visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries to tune model, get different metric scores, and split data\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "#libraries to help with model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier)\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('BankChurners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>712389108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>2107</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.651</td>\n",
       "      <td>4058</td>\n",
       "      <td>83</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>718388733</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>38</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>College</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>1259</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>8677</td>\n",
       "      <td>96</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>710109633</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>College</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>1061</td>\n",
       "      <td>8810.0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>1683</td>\n",
       "      <td>34</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>717331758</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$120K +</td>\n",
       "      <td>Blue</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>34516.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>31999.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>4228</td>\n",
       "      <td>83</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>709460883</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>38</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>2437</td>\n",
       "      <td>46</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>789105183</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Post-Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Silver</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34516.0</td>\n",
       "      <td>2488</td>\n",
       "      <td>32028.0</td>\n",
       "      <td>0.552</td>\n",
       "      <td>4401</td>\n",
       "      <td>87</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>771342183</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>2314</td>\n",
       "      <td>43</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>708174708</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5535.0</td>\n",
       "      <td>1276</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1764</td>\n",
       "      <td>38</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>718076733</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Silver</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25824.0</td>\n",
       "      <td>1170</td>\n",
       "      <td>24654.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>3101</td>\n",
       "      <td>73</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>821889858</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1477</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0.662</td>\n",
       "      <td>2493</td>\n",
       "      <td>44</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "6498  712389108  Existing Customer            43      F                2   \n",
       "9013  718388733  Existing Customer            38      F                1   \n",
       "2053  710109633  Existing Customer            39      M                2   \n",
       "3211  717331758  Existing Customer            44      M                4   \n",
       "5559  709460883  Attrited Customer            38      F                2   \n",
       "6106  789105183  Existing Customer            54      M                3   \n",
       "4150  771342183  Attrited Customer            53      F                3   \n",
       "2205  708174708  Existing Customer            38      M                4   \n",
       "4145  718076733  Existing Customer            43      M                1   \n",
       "5324  821889858  Attrited Customer            50      F                1   \n",
       "\n",
       "     Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "6498        Graduate        Married  Less than $40K          Blue   \n",
       "9013         College        Unknown  Less than $40K          Blue   \n",
       "2053         College        Married     $60K - $80K          Blue   \n",
       "3211        Graduate        Married         $120K +          Blue   \n",
       "5559       Doctorate        Married  Less than $40K          Blue   \n",
       "6106   Post-Graduate         Single    $80K - $120K        Silver   \n",
       "4150        Graduate         Single     $40K - $60K          Blue   \n",
       "2205        Graduate        Married     $40K - $60K          Blue   \n",
       "4145        Graduate         Single     $60K - $80K        Silver   \n",
       "5324       Doctorate         Single         Unknown          Blue   \n",
       "\n",
       "      Months_on_book  ...  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "6498              36  ...                       3                      2   \n",
       "9013              32  ...                       3                      3   \n",
       "2053              31  ...                       3                      2   \n",
       "3211              32  ...                       3                      4   \n",
       "5559              28  ...                       2                      4   \n",
       "6106              42  ...                       1                      2   \n",
       "4150              40  ...                       3                      2   \n",
       "2205              27  ...                       2                      4   \n",
       "4145              31  ...                       3                      3   \n",
       "5324              46  ...                       4                      3   \n",
       "\n",
       "      Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "6498        2570.0                 2107            463.0   \n",
       "9013        2609.0                 1259           1350.0   \n",
       "2053        9871.0                 1061           8810.0   \n",
       "3211       34516.0                 2517          31999.0   \n",
       "5559        1614.0                    0           1614.0   \n",
       "6106       34516.0                 2488          32028.0   \n",
       "4150        1625.0                    0           1625.0   \n",
       "2205        5535.0                 1276           4259.0   \n",
       "4145       25824.0                 1170          24654.0   \n",
       "5324        1970.0                 1477            493.0   \n",
       "\n",
       "      Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "6498                 0.651             4058              83   \n",
       "9013                 0.871             8677              96   \n",
       "2053                 0.545             1683              34   \n",
       "3211                 0.765             4228              83   \n",
       "5559                 0.609             2437              46   \n",
       "6106                 0.552             4401              87   \n",
       "4150                 0.689             2314              43   \n",
       "2205                 0.636             1764              38   \n",
       "4145                 0.684             3101              73   \n",
       "5324                 0.662             2493              44   \n",
       "\n",
       "      Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "6498                0.766                  0.820  \n",
       "9013                0.627                  0.483  \n",
       "2053                0.478                  0.107  \n",
       "3211                0.596                  0.073  \n",
       "5559                0.438                  0.000  \n",
       "6106                0.776                  0.072  \n",
       "4150                0.433                  0.000  \n",
       "2205                0.900                  0.231  \n",
       "4145                0.780                  0.045  \n",
       "5324                0.571                  0.750  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1) \n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CLIENTNUM                 10127 non-null  int64  \n",
      " 1   Attrition_Flag            10127 non-null  object \n",
      " 2   Customer_Age              10127 non-null  int64  \n",
      " 3   Gender                    10127 non-null  object \n",
      " 4   Dependent_count           10127 non-null  int64  \n",
      " 5   Education_Level           10127 non-null  object \n",
      " 6   Marital_Status            10127 non-null  object \n",
      " 7   Income_Category           10127 non-null  object \n",
      " 8   Card_Category             10127 non-null  object \n",
      " 9   Months_on_book            10127 non-null  int64  \n",
      " 10  Total_Relationship_Count  10127 non-null  int64  \n",
      " 11  Months_Inactive_12_mon    10127 non-null  int64  \n",
      " 12  Contacts_Count_12_mon     10127 non-null  int64  \n",
      " 13  Credit_Limit              10127 non-null  float64\n",
      " 14  Total_Revolving_Bal       10127 non-null  int64  \n",
      " 15  Avg_Open_To_Buy           10127 non-null  float64\n",
      " 16  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n",
      " 17  Total_Trans_Amt           10127 non-null  int64  \n",
      " 18  Total_Trans_Ct            10127 non-null  int64  \n",
      " 19  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n",
      " 20  Avg_Utilization_Ratio     10127 non-null  float64\n",
      "dtypes: float64(5), int64(10), object(6)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIENTNUM                   10127\n",
       "Attrition_Flag                  2\n",
       "Customer_Age                   45\n",
       "Gender                          2\n",
       "Dependent_count                 6\n",
       "Education_Level                 7\n",
       "Marital_Status                  4\n",
       "Income_Category                 6\n",
       "Card_Category                   4\n",
       "Months_on_book                 44\n",
       "Total_Relationship_Count        6\n",
       "Months_Inactive_12_mon          7\n",
       "Contacts_Count_12_mon           7\n",
       "Credit_Limit                 6205\n",
       "Total_Revolving_Bal          1974\n",
       "Avg_Open_To_Buy              6813\n",
       "Total_Amt_Chng_Q4_Q1         1158\n",
       "Total_Trans_Amt              5033\n",
       "Total_Trans_Ct                126\n",
       "Total_Ct_Chng_Q4_Q1           830\n",
       "Avg_Utilization_Ratio         964\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Avg_Utilization_Ratio       0\n",
       "Months_on_book              0\n",
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Total_Relationship_Count    0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "CLIENTNUM                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sort_values(ascending = False) #identify missing values, also isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>7.391776e+08</td>\n",
       "      <td>3.690378e+07</td>\n",
       "      <td>708082083.0</td>\n",
       "      <td>7.130368e+08</td>\n",
       "      <td>7.179264e+08</td>\n",
       "      <td>7.731435e+08</td>\n",
       "      <td>8.283431e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Age</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>4.632596e+01</td>\n",
       "      <td>8.016814e+00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>7.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependent_count</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>2.346203e+00</td>\n",
       "      <td>1.298908e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Months_on_book</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>3.592841e+01</td>\n",
       "      <td>7.986416e+00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>5.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>3.812580e+00</td>\n",
       "      <td>1.554408e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>2.341167e+00</td>\n",
       "      <td>1.010622e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>2.455317e+00</td>\n",
       "      <td>1.106225e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Limit</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>8.631954e+03</td>\n",
       "      <td>9.088777e+03</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>2.555000e+03</td>\n",
       "      <td>4.549000e+03</td>\n",
       "      <td>1.106750e+04</td>\n",
       "      <td>3.451600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>1.162814e+03</td>\n",
       "      <td>8.149873e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.590000e+02</td>\n",
       "      <td>1.276000e+03</td>\n",
       "      <td>1.784000e+03</td>\n",
       "      <td>2.517000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>7.469140e+03</td>\n",
       "      <td>9.090685e+03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.324500e+03</td>\n",
       "      <td>3.474000e+03</td>\n",
       "      <td>9.859000e+03</td>\n",
       "      <td>3.451600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>7.599407e-01</td>\n",
       "      <td>2.192068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.310000e-01</td>\n",
       "      <td>7.360000e-01</td>\n",
       "      <td>8.590000e-01</td>\n",
       "      <td>3.397000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>4.404086e+03</td>\n",
       "      <td>3.397129e+03</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2.155500e+03</td>\n",
       "      <td>3.899000e+03</td>\n",
       "      <td>4.741000e+03</td>\n",
       "      <td>1.848400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>6.485869e+01</td>\n",
       "      <td>2.347257e+01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>6.700000e+01</td>\n",
       "      <td>8.100000e+01</td>\n",
       "      <td>1.390000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>7.122224e-01</td>\n",
       "      <td>2.380861e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.820000e-01</td>\n",
       "      <td>7.020000e-01</td>\n",
       "      <td>8.180000e-01</td>\n",
       "      <td>3.714000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <td>10127.0</td>\n",
       "      <td>2.748936e-01</td>\n",
       "      <td>2.756915e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.300000e-02</td>\n",
       "      <td>1.760000e-01</td>\n",
       "      <td>5.030000e-01</td>\n",
       "      <td>9.990000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count          mean           std          min  \\\n",
       "CLIENTNUM                 10127.0  7.391776e+08  3.690378e+07  708082083.0   \n",
       "Customer_Age              10127.0  4.632596e+01  8.016814e+00         26.0   \n",
       "Dependent_count           10127.0  2.346203e+00  1.298908e+00          0.0   \n",
       "Months_on_book            10127.0  3.592841e+01  7.986416e+00         13.0   \n",
       "Total_Relationship_Count  10127.0  3.812580e+00  1.554408e+00          1.0   \n",
       "Months_Inactive_12_mon    10127.0  2.341167e+00  1.010622e+00          0.0   \n",
       "Contacts_Count_12_mon     10127.0  2.455317e+00  1.106225e+00          0.0   \n",
       "Credit_Limit              10127.0  8.631954e+03  9.088777e+03       1438.3   \n",
       "Total_Revolving_Bal       10127.0  1.162814e+03  8.149873e+02          0.0   \n",
       "Avg_Open_To_Buy           10127.0  7.469140e+03  9.090685e+03          3.0   \n",
       "Total_Amt_Chng_Q4_Q1      10127.0  7.599407e-01  2.192068e-01          0.0   \n",
       "Total_Trans_Amt           10127.0  4.404086e+03  3.397129e+03        510.0   \n",
       "Total_Trans_Ct            10127.0  6.485869e+01  2.347257e+01         10.0   \n",
       "Total_Ct_Chng_Q4_Q1       10127.0  7.122224e-01  2.380861e-01          0.0   \n",
       "Avg_Utilization_Ratio     10127.0  2.748936e-01  2.756915e-01          0.0   \n",
       "\n",
       "                                   25%           50%           75%  \\\n",
       "CLIENTNUM                 7.130368e+08  7.179264e+08  7.731435e+08   \n",
       "Customer_Age              4.100000e+01  4.600000e+01  5.200000e+01   \n",
       "Dependent_count           1.000000e+00  2.000000e+00  3.000000e+00   \n",
       "Months_on_book            3.100000e+01  3.600000e+01  4.000000e+01   \n",
       "Total_Relationship_Count  3.000000e+00  4.000000e+00  5.000000e+00   \n",
       "Months_Inactive_12_mon    2.000000e+00  2.000000e+00  3.000000e+00   \n",
       "Contacts_Count_12_mon     2.000000e+00  2.000000e+00  3.000000e+00   \n",
       "Credit_Limit              2.555000e+03  4.549000e+03  1.106750e+04   \n",
       "Total_Revolving_Bal       3.590000e+02  1.276000e+03  1.784000e+03   \n",
       "Avg_Open_To_Buy           1.324500e+03  3.474000e+03  9.859000e+03   \n",
       "Total_Amt_Chng_Q4_Q1      6.310000e-01  7.360000e-01  8.590000e-01   \n",
       "Total_Trans_Amt           2.155500e+03  3.899000e+03  4.741000e+03   \n",
       "Total_Trans_Ct            4.500000e+01  6.700000e+01  8.100000e+01   \n",
       "Total_Ct_Chng_Q4_Q1       5.820000e-01  7.020000e-01  8.180000e-01   \n",
       "Avg_Utilization_Ratio     2.300000e-02  1.760000e-01  5.030000e-01   \n",
       "\n",
       "                                   max  \n",
       "CLIENTNUM                 8.283431e+08  \n",
       "Customer_Age              7.300000e+01  \n",
       "Dependent_count           5.000000e+00  \n",
       "Months_on_book            5.600000e+01  \n",
       "Total_Relationship_Count  6.000000e+00  \n",
       "Months_Inactive_12_mon    6.000000e+00  \n",
       "Contacts_Count_12_mon     6.000000e+00  \n",
       "Credit_Limit              3.451600e+04  \n",
       "Total_Revolving_Bal       2.517000e+03  \n",
       "Avg_Open_To_Buy           3.451600e+04  \n",
       "Total_Amt_Chng_Q4_Q1      3.397000e+00  \n",
       "Total_Trans_Amt           1.848400e+04  \n",
       "Total_Trans_Ct            1.390000e+02  \n",
       "Total_Ct_Chng_Q4_Q1       3.714000e+00  \n",
       "Avg_Utilization_Ratio     9.990000e-01  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant column - CLIENTNUM is a unique ID \n",
    "\n",
    "data.drop(columns=[\"CLIENTNUM\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <td>10127</td>\n",
       "      <td>2</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Age</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.326</td>\n",
       "      <td>8.01681</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>10127</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>5358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependent_count</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3462</td>\n",
       "      <td>1.29891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_Level</th>\n",
       "      <td>10127</td>\n",
       "      <td>7</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Status</th>\n",
       "      <td>10127</td>\n",
       "      <td>4</td>\n",
       "      <td>Married</td>\n",
       "      <td>4687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_Category</th>\n",
       "      <td>10127</td>\n",
       "      <td>6</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>3561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Card_Category</th>\n",
       "      <td>10127</td>\n",
       "      <td>4</td>\n",
       "      <td>Blue</td>\n",
       "      <td>9436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Months_on_book</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.9284</td>\n",
       "      <td>7.98642</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.81258</td>\n",
       "      <td>1.55441</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.34117</td>\n",
       "      <td>1.01062</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.45532</td>\n",
       "      <td>1.10623</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Limit</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8631.95</td>\n",
       "      <td>9088.78</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>2555</td>\n",
       "      <td>4549</td>\n",
       "      <td>11067.5</td>\n",
       "      <td>34516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1162.81</td>\n",
       "      <td>814.987</td>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>1276</td>\n",
       "      <td>1784</td>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7469.14</td>\n",
       "      <td>9090.69</td>\n",
       "      <td>3</td>\n",
       "      <td>1324.5</td>\n",
       "      <td>3474</td>\n",
       "      <td>9859</td>\n",
       "      <td>34516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759941</td>\n",
       "      <td>0.219207</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.859</td>\n",
       "      <td>3.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4404.09</td>\n",
       "      <td>3397.13</td>\n",
       "      <td>510</td>\n",
       "      <td>2155.5</td>\n",
       "      <td>3899</td>\n",
       "      <td>4741</td>\n",
       "      <td>18484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.8587</td>\n",
       "      <td>23.4726</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712222</td>\n",
       "      <td>0.238086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.818</td>\n",
       "      <td>3.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <td>10127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274894</td>\n",
       "      <td>0.275691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count unique                top  freq      mean  \\\n",
       "Attrition_Flag            10127      2  Existing Customer  8500       NaN   \n",
       "Customer_Age              10127    NaN                NaN   NaN    46.326   \n",
       "Gender                    10127      2                  F  5358       NaN   \n",
       "Dependent_count           10127    NaN                NaN   NaN    2.3462   \n",
       "Education_Level           10127      7           Graduate  3128       NaN   \n",
       "Marital_Status            10127      4            Married  4687       NaN   \n",
       "Income_Category           10127      6     Less than $40K  3561       NaN   \n",
       "Card_Category             10127      4               Blue  9436       NaN   \n",
       "Months_on_book            10127    NaN                NaN   NaN   35.9284   \n",
       "Total_Relationship_Count  10127    NaN                NaN   NaN   3.81258   \n",
       "Months_Inactive_12_mon    10127    NaN                NaN   NaN   2.34117   \n",
       "Contacts_Count_12_mon     10127    NaN                NaN   NaN   2.45532   \n",
       "Credit_Limit              10127    NaN                NaN   NaN   8631.95   \n",
       "Total_Revolving_Bal       10127    NaN                NaN   NaN   1162.81   \n",
       "Avg_Open_To_Buy           10127    NaN                NaN   NaN   7469.14   \n",
       "Total_Amt_Chng_Q4_Q1      10127    NaN                NaN   NaN  0.759941   \n",
       "Total_Trans_Amt           10127    NaN                NaN   NaN   4404.09   \n",
       "Total_Trans_Ct            10127    NaN                NaN   NaN   64.8587   \n",
       "Total_Ct_Chng_Q4_Q1       10127    NaN                NaN   NaN  0.712222   \n",
       "Avg_Utilization_Ratio     10127    NaN                NaN   NaN  0.274894   \n",
       "\n",
       "                               std     min     25%    50%      75%    max  \n",
       "Attrition_Flag                 NaN     NaN     NaN    NaN      NaN    NaN  \n",
       "Customer_Age               8.01681      26      41     46       52     73  \n",
       "Gender                         NaN     NaN     NaN    NaN      NaN    NaN  \n",
       "Dependent_count            1.29891       0       1      2        3      5  \n",
       "Education_Level                NaN     NaN     NaN    NaN      NaN    NaN  \n",
       "Marital_Status                 NaN     NaN     NaN    NaN      NaN    NaN  \n",
       "Income_Category                NaN     NaN     NaN    NaN      NaN    NaN  \n",
       "Card_Category                  NaN     NaN     NaN    NaN      NaN    NaN  \n",
       "Months_on_book             7.98642      13      31     36       40     56  \n",
       "Total_Relationship_Count   1.55441       1       3      4        5      6  \n",
       "Months_Inactive_12_mon     1.01062       0       2      2        3      6  \n",
       "Contacts_Count_12_mon      1.10623       0       2      2        3      6  \n",
       "Credit_Limit               9088.78  1438.3    2555   4549  11067.5  34516  \n",
       "Total_Revolving_Bal        814.987       0     359   1276     1784   2517  \n",
       "Avg_Open_To_Buy            9090.69       3  1324.5   3474     9859  34516  \n",
       "Total_Amt_Chng_Q4_Q1      0.219207       0   0.631  0.736    0.859  3.397  \n",
       "Total_Trans_Amt            3397.13     510  2155.5   3899     4741  18484  \n",
       "Total_Trans_Ct             23.4726      10      45     67       81    139  \n",
       "Total_Ct_Chng_Q4_Q1       0.238086       0   0.582  0.702    0.818  3.714  \n",
       "Avg_Utilization_Ratio     0.275691       0   0.023  0.176    0.503  0.999  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data[\"Gender\"] = OneHotEncoder(sparse=False).fit_transform(data[['Gender']])\n",
    "data[\"Education_Level\"] = OneHotEncoder(sparse=False).fit_transform(data[['Education_Level']])\n",
    "data[\"Marital_Status\"] = OneHotEncoder(sparse=False).fit_transform(data[['Marital_Status']])\n",
    "data[\"Income_Category\"] = OneHotEncoder(sparse=False).fit_transform(data[['Income_Category']])\n",
    "data[\"Card_Category\"] = OneHotEncoder(sparse=False).fit_transform(data[['Card_Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Attrition_Flag\"] = OneHotEncoder(sparse=False).fit_transform(data[['Attrition_Flag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"Attrition_Flag\")\n",
    "Y = data[\"Attrition_Flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7088, 19) (3039, 19)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=1, stratify=Y\n",
    ")\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>8427.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attrition_Flag  Customer_Age  Gender  Dependent_count  Education_Level  \\\n",
       "0                 0.0            45     0.0                3              0.0   \n",
       "1                 0.0            49     1.0                5              0.0   \n",
       "2                 0.0            51     0.0                3              0.0   \n",
       "3                 0.0            40     1.0                4              0.0   \n",
       "4                 0.0            40     0.0                3              0.0   \n",
       "...               ...           ...     ...              ...              ...   \n",
       "10122             0.0            50     0.0                2              0.0   \n",
       "10123             1.0            41     0.0                2              0.0   \n",
       "10124             1.0            44     1.0                1              0.0   \n",
       "10125             1.0            30     0.0                2              0.0   \n",
       "10126             1.0            43     1.0                2              0.0   \n",
       "\n",
       "       Marital_Status  Income_Category  Card_Category  Months_on_book  \\\n",
       "0                 0.0              0.0            1.0              39   \n",
       "1                 0.0              0.0            1.0              44   \n",
       "2                 0.0              0.0            1.0              36   \n",
       "3                 0.0              0.0            1.0              34   \n",
       "4                 0.0              0.0            1.0              21   \n",
       "...               ...              ...            ...             ...   \n",
       "10122             0.0              0.0            1.0              40   \n",
       "10123             1.0              0.0            1.0              25   \n",
       "10124             0.0              0.0            1.0              36   \n",
       "10125             0.0              0.0            1.0              36   \n",
       "10126             0.0              0.0            0.0              25   \n",
       "\n",
       "       Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0                             5                       1   \n",
       "1                             6                       1   \n",
       "2                             4                       1   \n",
       "3                             3                       4   \n",
       "4                             5                       1   \n",
       "...                         ...                     ...   \n",
       "10122                         3                       2   \n",
       "10123                         4                       2   \n",
       "10124                         5                       3   \n",
       "10125                         4                       3   \n",
       "10126                         6                       2   \n",
       "\n",
       "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                          3       12691.0                  777   \n",
       "1                          2        8256.0                  864   \n",
       "2                          0        3418.0                    0   \n",
       "3                          1        3313.0                 2517   \n",
       "4                          0        4716.0                    0   \n",
       "...                      ...           ...                  ...   \n",
       "10122                      3        4003.0                 1851   \n",
       "10123                      3        4277.0                 2186   \n",
       "10124                      4        5409.0                    0   \n",
       "10125                      3        5281.0                    0   \n",
       "10126                      4       10388.0                 1961   \n",
       "\n",
       "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0              11914.0                 1.335             1144              42   \n",
       "1               7392.0                 1.541             1291              33   \n",
       "2               3418.0                 2.594             1887              20   \n",
       "3                796.0                 1.405             1171              20   \n",
       "4               4716.0                 2.175              816              28   \n",
       "...                ...                   ...              ...             ...   \n",
       "10122           2152.0                 0.703            15476             117   \n",
       "10123           2091.0                 0.804             8764              69   \n",
       "10124           5409.0                 0.819            10291              60   \n",
       "10125           5281.0                 0.535             8395              62   \n",
       "10126           8427.0                 0.703            10294              61   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0                    1.625                  0.061  \n",
       "1                    3.714                  0.105  \n",
       "2                    2.333                  0.000  \n",
       "3                    2.333                  0.760  \n",
       "4                    2.500                  0.000  \n",
       "...                    ...                    ...  \n",
       "10122                0.857                  0.462  \n",
       "10123                0.683                  0.511  \n",
       "10124                0.818                  0.000  \n",
       "10125                0.722                  0.000  \n",
       "10126                0.649                  0.189  \n",
       "\n",
       "[10127 rows x 20 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation criterion:\n",
    "\n",
    "#### Model can make wrong predictions as:\n",
    "1. Predicting a customer will attrite - Loss of resources if he does not \n",
    "2. Predicting a customer will not attrite and stay as existing client - Loss of opportunity if he really does \n",
    "\n",
    "#### Which case is more important? \n",
    "* Predicting that customer will not attrite but he will i.e. losing of a client and thus income for the company because that customer will not be targeted by the marketing team when he should be targeted. Losing a client is more costly than having to search for another client. Predicting that a customer will attrite but he is not is not going to cost as much except for the targeting resources. \n",
    "\n",
    "#### How to reduce this loss i.e need to reduce False Negatives?\n",
    "* Company wants Recall to be maximized, greater the Recall fewer the chances of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 58.2985547569364\n",
      "RF: 81.12180230311463\n",
      "GBM: 83.9315248473607\n",
      "ADB: 84.02117628873947\n",
      "[17:54:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:54:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:54:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:54:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:54:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB: 86.6539145219878\n",
      "DTREE: 78.75144910734988\n"
     ]
    }
   ],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending pipelines for each model into the list\n",
    "models.append(\n",
    "    (\n",
    "        \"LR\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"log_reg\", LogisticRegression(random_state=1)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"RF\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"random_forest\", RandomForestClassifier(random_state=1)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"GBM\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"gradient_boosting\", GradientBoostingClassifier(random_state=1)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"ADB\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"adaboost\", AdaBoostClassifier(random_state=1)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"XGB\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"xgboost\", XGBClassifier(random_state=1)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"DTREE\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"decision_tree\", DecisionTreeClassifier(random_state=1)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "results = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "for name, model in models:\n",
    "    scoring = \"recall\"\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring=scoring, cv=kfold\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Function to calculate different metric scores of the model - Accuracy, Recall and Precision\n",
    "def get_metrics_score(model, flag=True):\n",
    "    \"\"\"\n",
    "    model: classifier to predict values of X\n",
    "\n",
    "    \"\"\"\n",
    "    # defining an empty list to store train and test results\n",
    "    score_list = []\n",
    "\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "\n",
    "    train_recall = metrics.recall_score(y_train, pred_train)\n",
    "    test_recall = metrics.recall_score(y_test, pred_test)\n",
    "\n",
    "    train_precision = metrics.precision_score(y_train, pred_train)\n",
    "    test_precision = metrics.precision_score(y_test, pred_test)\n",
    "\n",
    "    score_list.extend(\n",
    "        (\n",
    "            train_acc,\n",
    "            test_acc,\n",
    "            train_recall,\n",
    "            test_recall,\n",
    "            train_precision,\n",
    "            test_precision,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True:\n",
    "        print(\"Accuracy on training set : \", model.score(X_train, y_train))\n",
    "        print(\"Accuracy on test set : \", model.score(X_test, y_test))\n",
    "        print(\"Recall on training set : \", metrics.recall_score(y_train, pred_train))\n",
    "        print(\"Recall on test set : \", metrics.recall_score(y_test, pred_test))\n",
    "        print(\"Precision on training set : \", metrics.precision_score(y_train, pred_train))\n",
    "        print(\"Precision on test set : \", metrics.precision_score(y_test, pred_test))\n",
    "\n",
    "    return score_list  # returning the list with train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create confusion matrix\n",
    "def make_confusion_matrix(model, y_actual, labels=[1, 0]):\n",
    "    \"\"\"\n",
    "    model: classifier to predict values of X\n",
    "    y_actual: ground truth\n",
    "\n",
    "    \"\"\"\n",
    "    y_predict = model.predict(X_test)\n",
    "    cm = metrics.confusion_matrix(y_actual, y_predict, labels=[0, 1])\n",
    "    df_cm = pd.DataFrame(\n",
    "        cm,\n",
    "        index=[i for i in [\"Actual - No\", \"Actual - Yes\"]],\n",
    "        columns=[i for i in [\"Predicted - No\", \"Predicted - Yes\"]],\n",
    "    )\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='recall'\n",
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=1)     #Setting number of splits equal to 5\n",
    "cv_result_bfr=cross_val_score(estimator=lr, X=X_train, y=y_train, scoring=scoring, cv=kfold)\n",
    "#Plotting boxplots for CV scores of model defined above\n",
    "plt.boxplot(cv_result_bfr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "scores_LR = get_metrics_score(lr,X_train,X_test,y_train,y_test)\n",
    "\n",
    "# creating confusion matrix\n",
    "make_confusion_matrix(lr,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling train data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before UpSampling, counts of label 'Yes': {}\".format(sum(y_train==1)))\n",
    "print(\"Before UpSampling, counts of label 'No': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 1 ,k_neighbors = 5, random_state=1)   #Synthetic Minority Over Sampling Technique\n",
    "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"After UpSampling, counts of label 'Yes': {}\".format(sum(y_train_over==1)))\n",
    "print(\"After UpSampling, counts of label 'No': {} \\n\".format(sum(y_train_over==0)))\n",
    "\n",
    "\n",
    "print('After UpSampling, the shape of train_X: {}'.format(X_train_over.shape))\n",
    "print('After UpSampling, the shape of train_y: {} \\n'.format(y_train_over.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_over = LogisticRegression(random_state = 1)\n",
    "\n",
    "# Training the basic logistic regression model with training set \n",
    "log_reg_over.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='recall'\n",
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=1)     #Setting number of splits equal to 5\n",
    "cv_result_over=cross_val_score(estimator=log_reg_over, X=X_train_over, y=y_train_over, scoring=scoring, cv=kfold)\n",
    "#Plotting boxplots for CV scores of model defined above\n",
    "plt.boxplot(cv_result_over)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "get_metrics_score(log_reg_over,X_train_over,X_test,y_train_over,y_test)\n",
    "\n",
    "# creating confusion matrix\n",
    "make_confusion_matrix(log_reg_over,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "lr_estimator = LogisticRegression(random_state=1,solver='saga')\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'C': np.arange(0.1,1.1,0.1)}\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(lr_estimator, parameters, scoring='recall')\n",
    "grid_obj = grid_obj.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "lr_estimator = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "lr_estimator.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "get_metrics_score(lr_estimator,X_train_over,X_test,y_train_over,y_test)\n",
    "\n",
    "# creating confusion matrix\n",
    "make_confusion_matrix(lr_estimator,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling train data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state = 1)\n",
    "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Under Sampling, counts of label 'Yes': {}\".format(sum(y_train==1)))\n",
    "print(\"Before Under Sampling, counts of label 'No': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "print(\"After Under Sampling, counts of label 'Yes': {}\".format(sum(y_train_un==1)))\n",
    "print(\"After Under Sampling, counts of label 'No': {} \\n\".format(sum(y_train_un==0)))\n",
    "\n",
    "print('After Under Sampling, the shape of train_X: {}'.format(X_train_un.shape))\n",
    "print('After Under Sampling, the shape of train_y: {} \\n'.format(y_train_un.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_under = LogisticRegression(random_state = 1)\n",
    "log_reg_under.fit(X_train_un,y_train_un )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='recall'\n",
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=1)     #Setting number of splits equal to 5\n",
    "cv_result_under=cross_val_score(estimator=log_reg_under, X=X_train_un, y=y_train_un, scoring=scoring, cv=kfold)\n",
    "#Plotting boxplots for CV scores of model defined above\n",
    "plt.boxplot(cv_result_under)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "get_metrics_score(log_reg_under,X_train_un,X_test,y_train_un,y_test)\n",
    "\n",
    "\n",
    "# creating confusion matrix\n",
    "make_confusion_matrix(log_reg_under,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Logistic Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list of model\n",
    "models = [lr]\n",
    "\n",
    "# defining empty lists to add train and test results\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "\n",
    "# looping through all the models to get the metrics score - Accuracy, Recall and Precision\n",
    "for model in models:\n",
    "    \n",
    "    j = get_metrics_score(model,X_train,X_test,y_train,y_test,False)\n",
    "    acc_train.append(j[0])\n",
    "    acc_test.append(j[1])\n",
    "    recall_train.append(j[2])\n",
    "    recall_test.append(j[3])\n",
    "    precision_train.append(j[4])\n",
    "    precision_test.append(j[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"XGBoost tuned with GridSearchCV\",\n",
    "            \"XGBoost tuned with RandomizedSearchCV\",\n",
    "            \"Decision tree tuned with GridSearchCV\",\n",
    "            \"Decision tree tuned with RandomizedSearchCV\"\n",
    "        ],\n",
    "        \"Train_Accuracy\": acc_train,\n",
    "        \"Test_Accuracy\": acc_test,\n",
    "        \"Train_Recall\": recall_train,\n",
    "        \"Test_Recall\": recall_test,\n",
    "        \"Train_Precision\": precision_train,\n",
    "        \"Test_Precision\": precision_test,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sorting models in decreasing order of test recall\n",
    "comparison_frame.sort_values(by=\"Test_Recall\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list of models\n",
    "models = [log_reg_over, lr_estimator]\n",
    "\n",
    "# looping through all the models to get the metrics score - Accuracy, Recall and Precision\n",
    "for model in models:\n",
    "    \n",
    "    j = get_metrics_score(model,X_train_over,X_test,y_train_over,y_test,False)\n",
    "    acc_train.append(j[0])\n",
    "    acc_test.append(j[1])\n",
    "    recall_train.append(j[2])\n",
    "    recall_test.append(j[3])\n",
    "    precision_train.append(j[4])\n",
    "    precision_test.append(j[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list of model\n",
    "models = [log_reg_under]\n",
    "\n",
    "# looping through all the models to get the metrics score - Accuracy, Recall and Precision\n",
    "for model in models:\n",
    "    \n",
    "    j = get_metrics_score(model,X_train_un,X_test,y_train_un,y_test,False)\n",
    "    acc_train.append(j[0])\n",
    "    acc_test.append(j[1])\n",
    "    recall_train.append(j[2])\n",
    "    recall_test.append(j[3])\n",
    "    precision_train.append(j[4])\n",
    "    precision_test.append(j[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['Logistic Regression','Logistic Regression on Oversampled data',\n",
    "                                          'Logistic Regression-Regularized (Oversampled data)','Logistic Regression on Undersampled data'], \n",
    "                                          'Train_Accuracy': acc_train,'Test_Accuracy': acc_test,\n",
    "                                          'Train_Recall':recall_train,'Test_Recall':recall_test,\n",
    "                                          'Train_Precision':precision_train,'Test_Precision':precision_test}) \n",
    "\n",
    "#Sorting models in decreasing order of test recall\n",
    "comparison_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding coefficients \n",
    "log_odds = log_reg_under.coef_[0]\n",
    "pd.DataFrame(log_odds, X_train_un.columns, columns=['coef']).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odds from coefficients \n",
    "odds = np.exp(log_reg_under.coef_[0]) # converting coefficients to odds\n",
    "pd.set_option('display.max_columns',None)  # removing limit from number of columns to display\n",
    "pd.DataFrame(odds, X_train.columns, columns=['odds']).T # adding the odds to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % change in odds \n",
    "perc_change_odds = (np.exp(log_reg_under.coef_[0])-1)*100 # finding the percentage change\n",
    "pd.set_option('display.max_columns',None) # removing limit from number of columns to display\n",
    "pd.DataFrame(perc_change_odds, X_train.columns, columns=['change_odds%']).T # adding the change_odds% to a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:{'adaboostclassifier__base_estimator': DecisionTreeClassifier(max_depth=2, random_state=1), 'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 70} \n",
      "Score: 0.8701058814436975\n",
      "CPU times: user 3.96 s, sys: 787 ms, total: 4.75 s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Creating pipeline\n",
    "pipe = make_pipeline(StandardScaler(), AdaBoostClassifier(random_state=1))\n",
    "\n",
    "# Parameter grid to pass in GridSearchCV\n",
    "param_grid = {\n",
    "    \"adaboostclassifier__n_estimators\": np.arange(10, 110, 10),\n",
    "    \"adaboostclassifier__learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
    "    \"adaboostclassifier__base_estimator\": [\n",
    "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Calling GridSearchCV\n",
    "grid_cv = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scorer, cv=5, n_jobs = -1)\n",
    "\n",
    "# Fitting parameters in GridSeachCV\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best Parameters:{} \\nScore: {}\".format(grid_cv.best_params_, grid_cv.best_score_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('adaboostclassifier',\n",
       "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
       "                                                                          random_state=1),\n",
       "                                    learning_rate=1, n_estimators=100,\n",
       "                                    random_state=1))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "abc_tuned1 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "        n_estimators=100,\n",
    "        learning_rate=1,\n",
    "        random_state=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "abc_tuned1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.9954853273137697\n",
      "Accuracy on test set :  0.9723593287265548\n",
      "Recall on training set :  0.9833187006145742\n",
      "Recall on test set :  0.9118852459016393\n",
      "Precision on training set :  0.9885260370697264\n",
      "Precision on test set :  0.9156378600823045\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "get_metrics_score(abc_tuned1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "make_confusion_matrix(abc_tuned1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'adaboostclassifier__n_estimators': 90, 'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__base_estimator': DecisionTreeClassifier(max_depth=2, random_state=1)} with CV score=0.8674588453512635:\n",
      "CPU times: user 3min 4s, sys: 1.76 s, total: 3min 6s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating pipeline\n",
    "pipe = make_pipeline(StandardScaler(), AdaBoostClassifier(random_state=1))\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"adaboostclassifier__n_estimators\": np.arange(10, 110, 10),\n",
    "    \"adaboostclassifier__learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
    "    \"adaboostclassifier__base_estimator\": [\n",
    "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
    "    ],\n",
    "}\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "abc_tuned2 = RandomizedSearchCV(estimator=pipe, param_distributions=param_grid, n_iter=50, scoring=scorer, cv=5, random_state=1)\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "abc_tuned2.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(abc_tuned2.best_params_,abc_tuned2.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('adaboostclassifier',\n",
       "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
       "                                                                          random_state=1),\n",
       "                                    learning_rate=1, n_estimators=100,\n",
       "                                    random_state=1))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "abc_tuned2 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "        n_estimators=100,\n",
    "        learning_rate=1,\n",
    "        random_state=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "abc_tuned2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.9954853273137697\n",
      "Accuracy on test set :  0.9723593287265548\n",
      "Recall on training set :  0.9833187006145742\n",
      "Recall on test set :  0.9118852459016393\n",
      "Precision on training set :  0.9885260370697264\n",
      "Precision on test set :  0.9156378600823045\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "get_metrics_score(abc_tuned2)\n",
    "\n",
    "# Creating confusion matrix\n",
    "make_confusion_matrix(abc_tuned2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "#Creating pipeline\n",
    "pipe=make_pipeline(StandardScaler(), XGBClassifier(random_state=1,eval_metric='logloss'))\n",
    "\n",
    "#Parameter grid to pass in GridSearchCV\n",
    "param_grid={'xgbclassifier__n_estimators':np.arange(50,300,50),'xgbclassifier__scale_pos_weight':[0,1,2,5,10],\n",
    "            'xgbclassifier__learning_rate':[0.01,0.1,0.2,0.05], 'xgbclassifier__gamma':[0,1,3,5],\n",
    "            'xgbclassifier__subsample':[0.7,0.8,0.9,1]}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "#Calling GridSearchCV\n",
    "grid_cv = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scorer, cv=5, n_jobs = -1)\n",
    "\n",
    "#Fitting parameters in GridSeachCV\n",
    "grid_cv.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(grid_cv.best_params_,grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "xgb_tuned1 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBClassifier(\n",
    "        random_state=1,\n",
    "        n_estimators=50,\n",
    "        scale_pos_weight=10,\n",
    "        subsample=0.9,\n",
    "        learning_rate=0.01,\n",
    "        gamma=5,\n",
    "        eval_metric='logloss',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "xgb_tuned1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating different metrics\n",
    "get_metrics_score(xgb_tuned1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "make_confusion_matrix(xgb_tuned1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "#Creating pipeline\n",
    "pipe=make_pipeline(StandardScaler(),XGBClassifier(random_state=1,eval_metric='logloss', n_estimators = 50))\n",
    "\n",
    "#Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={'xgbclassifier__n_estimators':np.arange(50,300,50),\n",
    "            'xgbclassifier__scale_pos_weight':[0,1,2,5,10],\n",
    "            'xgbclassifier__learning_rate':[0.01,0.1,0.2,0.05],\n",
    "            'xgbclassifier__gamma':[0,1,3,5],\n",
    "            'xgbclassifier__subsample':[0.7,0.8,0.9,1],\n",
    "           'xgbclassifier__max_depth':np.arange(1,10,1),\n",
    "            'xgbclassifier__reg_lambda':[0,1,2,5,10]}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(estimator=pipe, param_distributions=param_grid, n_iter=50, scoring=scorer, cv=5, random_state=1)\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "xgb_tuned2 = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"XGB\",\n",
    "            XGBClassifier(\n",
    "                random_state=1,\n",
    "                n_estimators=200,\n",
    "                scale_pos_weight=10,\n",
    "                gamma=1,\n",
    "                subsample=0.9,\n",
    "                learning_rate= 0.01,\n",
    "                eval_metric='logloss', max_depth = 2, reg_lambda = 2\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# Fit the model on training data\n",
    "xgb_tuned2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating different metrics\n",
    "get_metrics_score(xgb_tuned2)\n",
    "\n",
    "# Creating confusion matrix\n",
    "make_confusion_matrix(xgb_tuned2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline\n",
    "pipe = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=1))\n",
    "\n",
    "# Parameter grid to pass in GridSearchCV\n",
    "param_grid = {\n",
    "    \"decisiontreeclassifier__criterion\": ['gini','entropy'],\n",
    "    \"decisiontreeclassifier__max_depth\": [3, 4, 5, None],\n",
    "    \"decisiontreeclassifier__min_samples_split\": [2,4,7,10,15]\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Calling GridSearchCV\n",
    "grid_cv = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scorer, cv=5)\n",
    "\n",
    "# Fitting parameters in GridSeachCV\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best Parameters:{} \\nScore: {}\".format(grid_cv.best_params_, grid_cv.best_score_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "dtree_tuned1 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier(random_state=1, criterion='gini', max_depth=None, min_samples_split=4),\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "dtree_tuned1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating different metrics\n",
    "get_metrics_score(dtree_tuned1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "make_confusion_matrix(dtree_tuned1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline\n",
    "pipe = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=1))\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \n",
    "     \"decisiontreeclassifier__criterion\": ['gini','entropy'],\n",
    "    \"decisiontreeclassifier__max_depth\": [3, 4, 5, None],\n",
    "    \"decisiontreeclassifier__min_samples_split\": [2,4,7,10,15]\n",
    "}\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(estimator=pipe, param_distributions=param_grid, n_iter=20, scoring=scorer, cv=5, random_state=1)\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "dtree_tuned2 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier(random_state=1, criterion='gini', max_depth=None, min_samples_split=7),\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "dtree_tuned2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating different metrics\n",
    "get_metrics_score(dtree_tuned2)\n",
    "\n",
    "# Creating confusion matrix\n",
    "make_confusion_matrix(dtree_tuned2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing All Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list of models\n",
    "models = [abc_tuned1, abc_tuned2, xgb_tuned1, xgb_tuned2,dtree_tuned1, dtree_tuned2]\n",
    "\n",
    "# defining empty lists to add train and test results\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "\n",
    "# looping through all the models to get the metrics score - Accuracy, Recall and Precision\n",
    "for model in models:\n",
    "\n",
    "    j = get_metrics_score(model, False)\n",
    "    acc_train.append(j[0])\n",
    "    acc_test.append(j[1])\n",
    "    recall_train.append(j[2])\n",
    "    recall_test.append(j[3])\n",
    "    precision_train.append(j[4])\n",
    "    precision_test.append(j[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Adaboost with GridSearchCV\",\n",
    "            \"Adaboost with RandomizedSearchCV\",\n",
    "            \"XGBoost with GridSearchCV\",\n",
    "            \"XGBoost with RandomizedSearchCV\",\n",
    "            \"Decision tree tuned with GridSearchCV\",\n",
    "            \"Decision tree tuned with RandomizedSearchCV\"\n",
    "    \n",
    "        ],\n",
    "        \"Train_Accuracy\": acc_train,\n",
    "        \"Test_Accuracy\": acc_test,\n",
    "        \"Train_Recall\": recall_train,\n",
    "        \"Test_Recall\": recall_test,\n",
    "        \"Train_Precision\": precision_train,\n",
    "        \"Test_Precision\": precision_test,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sorting models in decreasing order of test recall\n",
    "comparison_frame.sort_values(by=\"Test_Recall\", ascending=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "importances = xgb_tuned1[1].feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
